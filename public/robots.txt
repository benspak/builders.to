# Robots.txt for Builders.to
# https://builders.to

User-agent: *
Allow: /

# Public pages - explicitly allowed for clarity
Allow: /feed
Allow: /projects
Allow: /projects/*
Allow: /companies
Allow: /companies/*
Allow: /services
Allow: /services/*
Allow: /events
Allow: /events/*
Allow: /local
Allow: /local/*
Allow: /listing/*
Allow: /streamers
Allow: /leaderboard
Allow: /map
Allow: /articles
Allow: /how-to
Allow: /how-to/*
Allow: /growth-hacks
Allow: /growth-hacks/*
Allow: /privacy
Allow: /terms

# Public builder profiles (top-level slugs)
# These are dynamically generated from usernames

# Protect API endpoints
Disallow: /api/

# Protect authentication pages
Disallow: /signin
Disallow: /verify-2fa

# Protect user-specific and authenticated pages
Disallow: /settings
Disallow: /notifications
Disallow: /my-companies
Disallow: /my-listings
Disallow: /purchases
Disallow: /updates

# Protect advertising management
Disallow: /ads/

# Protect discovery and accountability (authenticated features)
Disallow: /discover
Disallow: /accountability
Disallow: /messages

# Protect service provider pages
Disallow: /services/new
Disallow: /services/*/edit

# Protect project management pages
Disallow: /projects/new
Disallow: /projects/*/edit

# Prevent indexing of file uploads directory patterns
Disallow: /uploads/

# Crawl-delay for politeness (optional, respected by some crawlers)
Crawl-delay: 1

# Sitemap location
Sitemap: https://builders.to/sitemap.xml

# AI Crawlers - llms.txt location
# See https://llmstxt.org/ for specification
# LLMs.txt: https://builders.to/llms.txt
